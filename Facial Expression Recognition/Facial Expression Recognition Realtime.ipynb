{"cells":[{"cell_type":"code","execution_count":null,"id":"legislative-trade","metadata":{"id":"legislative-trade"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import cv2\n","\n","import dlib\n","import pickle"]},{"cell_type":"code","execution_count":null,"id":"arranged-provider","metadata":{"id":"arranged-provider"},"outputs":[],"source":["def get_model():\n","    backbone = tf.keras.applications.EfficientNetB2(\n","        input_shape=(96, 96, 3),\n","        include_top=False,\n","        weights=None\n","    )\n","    model = tf.keras.Sequential([\n","        backbone,\n","        tf.keras.layers.GlobalAveragePooling2D(),\n","        tf.keras.layers.Dropout(0.3),\n","        tf.keras.layers.Dense(128, activation='relu'),\n","        tf.keras.layers.Dense(7, activation='softmax')\n","    ])\n","    return model"]},{"cell_type":"code","execution_count":null,"id":"double-subscriber","metadata":{"id":"double-subscriber"},"outputs":[],"source":["model = get_model()\n","model.load_weights(\"best_weights.h5\") # Load the saved weights "]},{"cell_type":"code","execution_count":null,"id":"documentary-twist","metadata":{"id":"documentary-twist","outputId":"b9cf4a16-adaa-42be-ae2f-93a249a02c83"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\users\\abhil\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py:315: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22.2.post1 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n","  UserWarning)\n"]}],"source":["# Load LabelEncoder \n","def load_object(name):\n","    pickle_obj = open(f\"{name}.pck\",\"rb\")\n","    obj = pickle.load(pickle_obj)\n","    return obj\n","\n","Le = load_object(\"LabelEncoder\")"]},{"cell_type":"code","execution_count":null,"id":"provincial-cambridge","metadata":{"id":"provincial-cambridge"},"outputs":[],"source":["def ProcessImage(image):\n","    image = tf.convert_to_tensor(image)\n","    image = tf.image.resize(image , [96 , 96] , method=\"bilinear\")\n","    image = tf.expand_dims(image , 0)\n","    return image\n","\n","def RealtimePrediction(image , model, encoder_):\n","    prediction = model.predict(image)\n","    prediction = np.argmax(prediction , axis = 1)\n","    return encoder_.inverse_transform(prediction)[0]\n","\n","def rect_to_bb(rect):\n","    x = rect.left()\n","    y = rect.top()\n","    w = rect.right() - x\n","    h = rect.bottom() - y\n","    return (x, y, w, h)"]},{"cell_type":"code","execution_count":null,"id":"diverse-measurement","metadata":{"id":"diverse-measurement"},"outputs":[],"source":["VideoCapture = cv2.VideoCapture(0)\n","\n","detector = dlib.get_frontal_face_detector()\n","\n","while True :\n","    \n","    ret , frame = VideoCapture.read() \n","    \n","    if not ret :\n","        break\n","\n","    gray = cv2.cvtColor( frame , cv2.COLOR_BGR2GRAY)\n","\n","    rects = detector(gray , 0)\n","\n","    if len(rects) >= 1 :\n","        for rect in rects :\n","            (x , y , w , h) = rect_to_bb(rect)\n","            img = gray[y-10 : y+h+10 , x-10 : x+w+10]\n","            \n","            if img.shape[0] == 0 or img.shape[1] == 0 :\n","                cv2.imshow(\"Frame\", frame)\n","                \n","            else :\n","                img = cv2.cvtColor(img , cv2.COLOR_GRAY2RGB)\n","                img = ProcessImage(img)\n","                out = RealtimePrediction(img , model , Le)\n","                cv2.rectangle(frame, (x, y), (x+w, y+h),(0, 255, 0), 2)\n","                z = y - 15 if y - 15 > 15 else y + 15\n","                cv2.putText(frame, str(out), (x, z), cv2.FONT_HERSHEY_SIMPLEX,0.75, (0, 255, 0), 2)\n","                \n","        cv2.imshow(\"Frame\", frame)\n","            \n","    else :\n","        cv2.imshow(\"Frame\", frame)\n","        \n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","        \n","VideoCapture.release()\n","cv2.destroyAllWindows()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Facial Expression Recognition Realtime.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}